{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Github Co-Pilot Usage\n",
    "\n",
    "This notebook will go over usage of github Co-pilot for Open Source projects which\n",
    "are part of a eco-system of other projects within a standards body. The aim in this\n",
    "case is to find out it's usefulness for day-today MaterialX development. When asked non programming questions \n",
    "co-pilot will reply `Sorry, but I can only assist with programming related questions.`.\n",
    "\n",
    "The hope is that since it is using [OpenAI Codex](https://openai.com/blog/openai-codex) that it\n",
    "can leverage the open source available in github repositories which house MaterialX and related project.\n",
    "\n",
    "Documentation for co-pilot can be found [here](https://docs.github.com/en/early-access/copilot/github-copilot-chat-transparency-note) for now. \n",
    "> This link will be updated when it is out of early access.\n",
    "\n",
    "Taken from the documents is this summary:\n",
    "\n",
    "> The system behavior of Copilot Chat can be broken down into several key steps.\n",
    ">\n",
    "> * Input processing: The input prompt from the user is pre-processed by the Copilot Chat system and sent to a large language model to get a response based on the context and prompt. User input can take the form of code snippets or plain language. The system is only intended to respond to coding-related questions.\n",
    "> * Language model analysis: The pre-processed prompt is then passed through the Copilot Chat language model, which is a neural network that has been trained on a large corpus of text data. The language model analyzes the input prompt and generates a response based on its understanding of the syntax and semantics of the input.\n",
    "> * Response generation: The language model generates a response based on its analysis of the input prompt. This response can take the form of generated code, code suggestions, or explanations of existing code.\n",
    "> * Output formatting: The response generated by Copilot Chat is formatted and presented to the user in a way that is easy to read and understand. This may include syntax highlighting, indentation, and other formatting features.\n",
    ">\n",
    "> Overall, the system behavior of Copilot Chat is designed to be intuitive and user-friendly, allowing you to ask coding-related questions and complete coding tasks quickly and easily. However, it is important for users to be aware of the potential limitations and risks of using Copilot Chat, and to carefully review and validate the responses generated by the system to ensure they are accurate and appropriate for the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Completion and Generation: \n",
    "\n",
    "* Can help with day to day code completion for well established APIs which are mostly static. \n",
    "* However there seems to be no way to specify specific API versions which is crucial to not use incorrect logic.\n",
    "* Good and bad in that it can glean the intent of code, and has the facility to write documentation explaining code. For example this works properly when writing new Python command line code.\n",
    "\n",
    "* For generation of MaterialX it mostly fails due to it's lack of knowledge of current MaterialX APIs and specification logic. This also appears to apply to other associated libraries such as Usd where the wrong answer is quite possible.\n",
    "* In the worst case it will \"invent\" API calls and data which doesn't even exist and often will mix the call syntax between APIs. For example it does this when using Usd and Mtlx used togehter.\n",
    "* It will try to complete intent based on comments supplied which sometimes works well but can often just try and \"parrot\" previously existing comments / code which wastes time.\n",
    "Chat, at least in VS-Code is not in  context, but a side-bar. So any recommendations need to copy and pasted into the actual code\n",
    "\n",
    "## Development Learning\n",
    "* To a certain extent co-pilot chat is useful as it can parse real Open Source documents and code to help with learning the API.\n",
    "For instance you can ask it to return MaterialX functions to manipulate nodes in a node graph. It will pull out a set of APIs and seems to mostly parse the API doc strings, or the online help. Usefulness dependents on the amount of effort put into this level of documentation.\n",
    "* Even simple questions such as providing a list of integrations which used MaterialX Python returned that MaterialX Viewer is written in Python and PySide for the UI which is blatently false.\n",
    "\n",
    "> There are several Python projects that use MaterialX. Here are some examples:\n",
    "> \n",
    "> 1. MaterialX Viewer: This is an open-source tool for viewing and editing MaterialX files. It is written in Python and uses > PySide for the user interface.\n",
    "\n",
    "## Admin:\n",
    "* Co-pilot can be selectly turned on / off but it's mostly at a global level and not per file or project.\n",
    "* At time of writing co-pilot has a Beta chat feature which requires a sign-up.\n",
    "\n",
    "## Natural Language Processing (Chat)\n",
    "* Chat can make suggestions along the way. Some may be usefu such as adding in error handling to code (e.g. adding in exception handling wrappers). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the answer to the query about nodegraph functions. Some of these APIs do not and have never existed\n",
    "such as \"connect()\". Sources of knowledge are unknown and cannot be validated so even if the information is correct it is unkown where it came from.\n",
    "\n",
    "\n",
    "> There are several MaterialX functions that can be used to manipulate nodes in a nodegraph. Here are some examples:\n",
    "> 1. `getNode(name)`: This function returns the node with the given name in the nodegraph.\n",
    "> 2. `addNode(type)`: This function adds a new node of the given type to the nodegraph and returns it.\n",
    "> 3. `removeNode(node)`: This function removes the given node from the nodegraph.\n",
    "> 4. `connect(source, output, destination, input)`: This function connects the output of the source node to the input of the destination node.\n",
    "> 5. `disconnect(source, output, destination, input)`: This function disconnects the output of the source node from the input of the destination node.\n",
    "> 6. `getUpstreamEdges(node, port)`: This function returns a list of all the edges that connect to the given input port of the given node.\n",
    "> 7. `getDownstreamEdges(node, port)`: This function returns a list of all the edges that connect to the given output port of the given node.\n",
    "\n",
    "> These functions can be used to create, modify, and delete nodes in a nodegraph, as well as to connect and disconnect nodes. They provide a powerful set of tools for manipulating nodegraphs in MaterialX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some code which was generated based on writing comments. \n",
    "* Some of the calls work but then obsoleted or invented API calls begin to be inserted. For example `setParameterValue()` existed in 2018 which what's included in the model be used. \n",
    "* Possibility due to a mis-assumption in intent, the \"wrong\" word can make the code generation instead try and spit out documentation. For example add in \"in MaterialX\" when trying to add a node spews out random documentation comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'MaterialX' has no attribute 'EXTERNAL_TYPE_STRING'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m image \u001b[39m=\u001b[39m nodegraph\u001b[39m.\u001b[39maddNode(\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[39m# Set the file parameter of the image node\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m image\u001b[39m.\u001b[39msetParameterValue(\u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mimage1.tif\u001b[39m\u001b[39m\"\u001b[39m, mx\u001b[39m.\u001b[39;49mEXTERNAL_TYPE_STRING)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'MaterialX' has no attribute 'EXTERNAL_TYPE_STRING'"
     ]
    }
   ],
   "source": [
    "# Import materialx module\n",
    "import MaterialX as mx\n",
    "\n",
    "# Create a document.\n",
    "doc = mx.createDocument()\n",
    "\n",
    "# Create a nodegraph\n",
    "nodegraph = doc.addNodeGraph()\n",
    "\n",
    "# Add a image node in MaterialX\n",
    "# The image node is a node that loads an image file\n",
    "# and outputs a color value\n",
    "# The image node has a file parameter that is used to\n",
    "# specify the image file to load\n",
    "# The image node has a color output that is used to\n",
    "# output the color value of the image\n",
    "# The image node has a uv input that is used to\n",
    "# specify the uv coordinates of the image to sample\n",
    "# The image node has a default input that is used to\n",
    "#   specify the default color value of the image\n",
    "#  if the image file cannot be loaded\n",
    "# The image node has a color_space input that is used to\n",
    "#  specify the color space of the image\n",
    "# The image node has a color_space output that is used to\n",
    "# output the color space of the image\n",
    "#  if the image file cannot be loaded\n",
    "# The image node has a alpha_mode input that is used to\n",
    "# specify the alpha mode of the image\n",
    "# The image node has a alpha_mode output that is used to\n",
    "# output the alpha mode of the image\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a premult input that is used to\n",
    "# specify whether the image is premultiplied\n",
    "# The image node has a premult output that is used to\n",
    "# output whether the image is premultiplied\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a mipmap input that is used to\n",
    "# specify whether the image is mipmapped\n",
    "# The image node has a mipmap output that is used to\n",
    "# output whether the image is mipmapped\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a uaddressmode input that is used to\n",
    "# specify the u address mode of the image\n",
    "# The image node has a uaddressmode output that is used to\n",
    "# output the u address mode of the image\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a vaddressmode input that is used to\n",
    "# specify the v address mode of the image\n",
    "# The image node has a vaddressmode output that is used to\n",
    "# output the v address mode of the image\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a filtertype input that is used to\n",
    "# specify the filter type of the image\n",
    "# The image node has a filtertype output that is used to\n",
    "# output the filter type of the image\n",
    "# if the image file cannot be loaded\n",
    "# The image node has a default_color_space input that is used to\n",
    "# specify the default color space of the image\n",
    "# The image node has a default_color_space output that is used to\n",
    "#  \n",
    "\n",
    "# Add a image node to the nodegraph\n",
    "image = nodegraph.addNode(\"image\")\n",
    "\n",
    "# Set the file parameter of the image node\n",
    "image.setParameterValue(\"file\", \"image1.tif\", mx.EXTERNAL_TYPE_STRING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to ask for explanation of a function, co-pilot chat does not take into account context and attempts to document all code. The follow-up assumptions on the \"next-question\" are also not in context but insteads proposes questions such as:\n",
    "\n",
    "> What are the best practies for formatting Python code according to PEP 8 guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaterialX.PyMaterialXCore.Node' object has no attribute 'getOutputPort'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Get the output port of the node\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m output_port \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mgetOutputPort(\u001b[39m\"\u001b[39m\u001b[39mout\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Traverse downstream from the output port\u001b[39;00m\n\u001b[0;32m      5\u001b[0m downstream_edges \u001b[39m=\u001b[39m nodegraph\u001b[39m.\u001b[39mgetDownstreamEdges(image, output_port)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MaterialX.PyMaterialXCore.Node' object has no attribute 'getOutputPort'"
     ]
    }
   ],
   "source": [
    "# Get the output port of the node\n",
    "output_port = image.getOutputPort(\"out\")\n",
    "\n",
    "# Traverse downstream from the output port\n",
    "downstream_edges = nodegraph.getDownstreamEdges(image, output_port)\n",
    "\n",
    "# Loop over the downstream edges and get the destination nodes\n",
    "for edge in downstream_edges:\n",
    "    destination_node = edge.getDestinationNode()\n",
    "    # Do something with the destination node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating Model Data\n",
    "\n",
    "There is a means to supplement the model, but with a target which is constantly moving like MaterialX, this is extra work and non-standard as every integration could be using different data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
